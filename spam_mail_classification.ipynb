{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfed84a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70f0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe20888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cd96612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "# Create WordNetLemmatizer object\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43000746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Kaggle Dataset/spam_email.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60c69981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>computer connection from cnn com wednesday es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>university degree obtain a prosperous future m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for all your answers guys i know i shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  ounce feather bowl hummingbird opec moment ala...\n",
       "1      1  wulvob get your medircations online qnb ikud v...\n",
       "2      0   computer connection from cnn com wednesday es...\n",
       "3      1  university degree obtain a prosperous future m...\n",
       "4      0  thanks for all your answers guys i know i shou..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "label\n",
    "    '1' indicates that the email is classified as spam.\n",
    "    '0' denotes that the email is legitimate (ham).\n",
    "text\n",
    "    This column contains the actual content of the email messages.\n",
    "'''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be55790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83448 entries, 0 to 83447\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   83448 non-null  int64 \n",
      " 1   text    83448 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6e25f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685c3a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['text'].apply(lambda x:len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9eccd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ounce feather bowl hummingbird opec moment ala...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>wulvob get your medircations online qnb ikud v...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>computer connection from cnn com wednesday es...</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>university degree obtain a prosperous future m...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>thanks for all your answers guys i know i shou...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  length\n",
       "0      1  ounce feather bowl hummingbird opec moment ala...      20\n",
       "1      1  wulvob get your medircations online qnb ikud v...     103\n",
       "2      0   computer connection from cnn com wednesday es...     339\n",
       "3      1  university degree obtain a prosperous future m...      77\n",
       "4      0  thanks for all your answers guys i know i shou...     223"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf79a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dc27afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing - Lemmatization and Stop words removal.\n",
    "def text_cleaning(txt):    \n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r'[^a-zA-Z\\s]', '', txt) \n",
    "    words = [word for word in txt.split(' ') if word not in stopwords.words(\"english\")]\n",
    "    txt = ' '.join(wnl.lemmatize(word) for word in words)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78e99cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['text'].apply(lambda x: text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e31711",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['processed'], y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74342c2",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    " Now can apply couple of methods. Let's start with word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2836877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def train_word2Vec_model(X_train):\n",
    "    sentences = list(X_train)\n",
    "\n",
    "    # Tokenize the sentences\n",
    "    tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "\n",
    "    # Train the Word2Vec model\n",
    "    model = Word2Vec(sentences=tokenized_sentences, vector_size=500, window=5, min_count=1, workers=4)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf645cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentence embeddings\n",
    "def get_sentence_vector(sentence, model):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)  # Average word vectors\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Zero vector for empty sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efde3ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_word2Vec_model(X_train)\n",
    "X_train = X_train.apply(lambda x:get_sentence_vector(x, model))\n",
    "X_test = X_test.apply(lambda x:get_sentence_vector(x, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31361e",
   "metadata": {},
   "source": [
    "# TFiDF Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2009da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdf = TfidfVectorizer()\n",
    "X_train = tfIdf.fit_transform(X_train)\n",
    "X_test = tfIdf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9046c3",
   "metadata": {},
   "source": [
    "# Bag of Words i.e Count Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countVec = CountVectorizer()\n",
    "X_train = countVec.fit_transform(X_train)\n",
    "X_test = countVec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5025306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us apply now different classification algorithms\n",
    "# Now let u perform all the ML techniques\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3eb9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArnabBiswas\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ======= For Logistic Regression ============\n",
      "Accuracy Score : 0.970461354104254 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7642  252]\n",
      " [ 241 8555]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      7894\n",
      "           1       0.97      0.97      0.97      8796\n",
      "\n",
      "    accuracy                           0.97     16690\n",
      "   macro avg       0.97      0.97      0.97     16690\n",
      "weighted avg       0.97      0.97      0.97     16690\n",
      "\n",
      "Execution time of program is:  4695.0599999999995 ms\n",
      "\n",
      " \n",
      " ======= For Support Vector Classifier ============\n",
      "Accuracy Score : 0.9838226482923906 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7712   99]\n",
      " [ 171 8708]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7811\n",
      "           1       0.99      0.98      0.98      8879\n",
      "\n",
      "    accuracy                           0.98     16690\n",
      "   macro avg       0.98      0.98      0.98     16690\n",
      "weighted avg       0.98      0.98      0.98     16690\n",
      "\n",
      "Execution time of program is:  205755.603 ms\n",
      "\n",
      " \n",
      " ======= For Decision Tree ============\n",
      "Accuracy Score : 0.9500898741761534 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7534  484]\n",
      " [ 349 8323]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      8018\n",
      "           1       0.95      0.96      0.95      8672\n",
      "\n",
      "    accuracy                           0.95     16690\n",
      "   macro avg       0.95      0.95      0.95     16690\n",
      "weighted avg       0.95      0.95      0.95     16690\n",
      "\n",
      "Execution time of program is:  158805.899 ms\n",
      "\n",
      " \n",
      " ======= For Random Forest ============\n",
      "Accuracy Score : 0.9831635710005991 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7707  105]\n",
      " [ 176 8702]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7812\n",
      "           1       0.99      0.98      0.98      8878\n",
      "\n",
      "    accuracy                           0.98     16690\n",
      "   macro avg       0.98      0.98      0.98     16690\n",
      "weighted avg       0.98      0.98      0.98     16690\n",
      "\n",
      "Execution time of program is:  283560.869 ms\n",
      "\n",
      " \n",
      " ======= For Neural Network ============\n",
      "Accuracy Score : 0.9880766926303176 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7771   87]\n",
      " [ 112 8720]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7858\n",
      "           1       0.99      0.99      0.99      8832\n",
      "\n",
      "    accuracy                           0.99     16690\n",
      "   macro avg       0.99      0.99      0.99     16690\n",
      "weighted avg       0.99      0.99      0.99     16690\n",
      "\n",
      "Execution time of program is:  63141.179000000004 ms\n",
      "\n",
      " \n",
      " ======= For Stochastic Gradient Descent ============\n",
      "Accuracy Score : 0.9700419412822049 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7631  248]\n",
      " [ 252 8559]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      7879\n",
      "           1       0.97      0.97      0.97      8811\n",
      "\n",
      "    accuracy                           0.97     16690\n",
      "   macro avg       0.97      0.97      0.97     16690\n",
      "weighted avg       0.97      0.97      0.97     16690\n",
      "\n",
      "Execution time of program is:  1479.36 ms\n",
      "\n",
      " \n",
      " ======= For XGBClassifier ============\n",
      "Accuracy Score : 0.9868184541641701 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7766  103]\n",
      " [ 117 8704]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7869\n",
      "           1       0.99      0.99      0.99      8821\n",
      "\n",
      "    accuracy                           0.99     16690\n",
      "   macro avg       0.99      0.99      0.99     16690\n",
      "weighted avg       0.99      0.99      0.99     16690\n",
      "\n",
      "Execution time of program is:  34802.292 ms\n",
      "\n",
      " \n",
      " ======= For ExtraTreesClassifier ============\n",
      "Accuracy Score : 0.984361893349311 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7719   97]\n",
      " [ 164 8710]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7816\n",
      "           1       0.99      0.98      0.99      8874\n",
      "\n",
      "    accuracy                           0.98     16690\n",
      "   macro avg       0.98      0.98      0.98     16690\n",
      "weighted avg       0.98      0.98      0.98     16690\n",
      "\n",
      "Execution time of program is:  59817.333 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArnabBiswas\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " ======= For AdaBoostClassifier ============\n",
      "Accuracy Score : 0.9576992210904733 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7550  373]\n",
      " [ 333 8434]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      7923\n",
      "           1       0.96      0.96      0.96      8767\n",
      "\n",
      "    accuracy                           0.96     16690\n",
      "   macro avg       0.96      0.96      0.96     16690\n",
      "weighted avg       0.96      0.96      0.96     16690\n",
      "\n",
      "Execution time of program is:  357411.455 ms\n",
      "\n",
      " \n",
      " ======= For GradientBoostingClassifier ============\n",
      "Accuracy Score : 0.9715398442180947 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7614  206]\n",
      " [ 269 8601]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      7820\n",
      "           1       0.98      0.97      0.97      8870\n",
      "\n",
      "    accuracy                           0.97     16690\n",
      "   macro avg       0.97      0.97      0.97     16690\n",
      "weighted avg       0.97      0.97      0.97     16690\n",
      "\n",
      "Execution time of program is:  2014662.941 ms\n",
      "\n",
      " \n",
      " ======= For KNN ============\n",
      "Accuracy Score : 0.9853205512282804 \n",
      "Confusion Matrix \n",
      "\n",
      "   [[7750  112]\n",
      " [ 133 8695]]\n",
      "\n",
      " Classification Report \n",
      " \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      7862\n",
      "           1       0.99      0.98      0.99      8828\n",
      "\n",
      "    accuracy                           0.99     16690\n",
      "   macro avg       0.99      0.99      0.99     16690\n",
      "weighted avg       0.99      0.99      0.99     16690\n",
      "\n",
      "Execution time of program is:  208.758 ms\n"
     ]
    }
   ],
   "source": [
    "models = {'Logistic Regression':LogisticRegression(), \n",
    "         'Support Vector Classifier':SVC(),'Decision Tree':DecisionTreeClassifier(),\n",
    "         'Random Forest':RandomForestClassifier(),'Neural Network':MLPClassifier(),\n",
    "         'Stochastic Gradient Descent':SGDClassifier(), 'XGBClassifier':XGBClassifier(),\n",
    "          'ExtraTreesClassifier':ExtraTreesClassifier(), 'AdaBoostClassifier':AdaBoostClassifier(),\n",
    "          'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "          'KNN':KNeighborsClassifier()}\n",
    "\n",
    "# While using word2Vec, please use the list() casting of X_train and X_test\n",
    "for model, algorithm in models.items():\n",
    "    start_time = datetime.now()    \n",
    "#     pipe = Pipeline([('model', algorithm)])    \n",
    "#     pipe.fit(X_train ,y_train)\n",
    "#     end_time = datetime.now() \n",
    "#     prediction = pipe.predict(X_test)\n",
    "\n",
    "    pipe = Pipeline([('model', algorithm)])    \n",
    "    pipe.fit(list(X_train) ,y_train)\n",
    "    end_time = datetime.now() \n",
    "    prediction = pipe.predict(list(X_test))\n",
    "\n",
    "    print(\"\\n \\n ======= For {} ============\".format(model))\n",
    "    print('Accuracy Score : {} '.format(accuracy_score(prediction,y_test)))\n",
    "    print('Confusion Matrix \\n\\n  ',confusion_matrix(prediction,y_test))\n",
    "    print('\\n Classification Report \\n ')\n",
    "    print(classification_report(prediction,y_test))\n",
    "    time_difference = (end_time - start_time).total_seconds() * 10**3\n",
    "    print(\"Execution time of program is: \", time_difference, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237669e",
   "metadata": {},
   "source": [
    "# Tensorflow and LSTM\n",
    "Now let us try some deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9df3254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9022 9195 8134 ...    0    0    0]\n",
      " [   1   24    1 ...    0    0    0]\n",
      " [ 394  989  129 ...   46 5113  900]\n",
      " ...\n",
      " [ 255 1555  313 ...    0    0    0]\n",
      " [1779  120  797 ...   86  639    2]\n",
      " [  24  231  520 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Step 1: Tokenize the text\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(df['processed'])\n",
    "sequences = tokenizer.texts_to_sequences(df['processed'])\n",
    "\n",
    "# Step 2: Pad the sequences (ensure same length for each document)\n",
    "max_length = 100  # You can choose a length depending on your dataset\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "print(padded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bfe4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                20736     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180801 (706.25 KB)\n",
      "Trainable params: 180801 (706.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Embedding layer converts tokens into dense vectors (embedding dimension is 16)\n",
    "    tf.keras.layers.Embedding(input_dim=10000, output_dim=16, input_length=max_length),\n",
    "    \n",
    "    # LSTM layer to process the sequences\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),  # 64 units in the LSTM\n",
    "    \n",
    "    # Output layer: binary classification (1 or 0)\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f3c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7831e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1669/1669 [==============================] - 84s 48ms/step - loss: 0.4263 - accuracy: 0.8119 - val_loss: 0.2051 - val_accuracy: 0.9470\n",
      "Epoch 2/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.2573 - accuracy: 0.8906 - val_loss: 0.1045 - val_accuracy: 0.9687\n",
      "Epoch 3/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0996 - accuracy: 0.9703 - val_loss: 0.1198 - val_accuracy: 0.9724\n",
      "Epoch 4/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0604 - accuracy: 0.9833 - val_loss: 0.0750 - val_accuracy: 0.9812\n",
      "Epoch 5/50\n",
      "1669/1669 [==============================] - 86s 51ms/step - loss: 0.0550 - accuracy: 0.9859 - val_loss: 0.0651 - val_accuracy: 0.9814\n",
      "Epoch 6/50\n",
      "1669/1669 [==============================] - 89s 53ms/step - loss: 0.0436 - accuracy: 0.9899 - val_loss: 0.0619 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "1669/1669 [==============================] - 88s 53ms/step - loss: 0.0346 - accuracy: 0.9920 - val_loss: 0.0687 - val_accuracy: 0.9840\n",
      "Epoch 8/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.0543 - val_accuracy: 0.9843\n",
      "Epoch 9/50\n",
      "1669/1669 [==============================] - 84s 51ms/step - loss: 0.0204 - accuracy: 0.9952 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
      "Epoch 10/50\n",
      "1669/1669 [==============================] - 86s 52ms/step - loss: 0.0167 - accuracy: 0.9961 - val_loss: 0.0627 - val_accuracy: 0.9834\n",
      "Epoch 11/50\n",
      "1669/1669 [==============================] - 84s 51ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0579 - val_accuracy: 0.9840\n",
      "Epoch 12/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0631 - val_accuracy: 0.9846\n",
      "Epoch 13/50\n",
      "1669/1669 [==============================] - 84s 51ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0669 - val_accuracy: 0.9842\n",
      "Epoch 14/50\n",
      "1669/1669 [==============================] - 91s 55ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0633 - val_accuracy: 0.9850\n",
      "Epoch 15/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0602 - val_accuracy: 0.9847\n",
      "Epoch 16/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 17/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0710 - val_accuracy: 0.9857\n",
      "Epoch 18/50\n",
      "1669/1669 [==============================] - 86s 51ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0686 - val_accuracy: 0.9848\n",
      "Epoch 19/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0710 - val_accuracy: 0.9850\n",
      "Epoch 20/50\n",
      "1669/1669 [==============================] - 86s 51ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0771 - val_accuracy: 0.9848\n",
      "Epoch 21/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0725 - val_accuracy: 0.9847\n",
      "Epoch 22/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1040 - val_accuracy: 0.9817\n",
      "Epoch 23/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0946 - val_accuracy: 0.9797\n",
      "Epoch 24/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.0799 - val_accuracy: 0.9839\n",
      "Epoch 25/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0902 - val_accuracy: 0.9839\n",
      "Epoch 26/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0758 - val_accuracy: 0.9842\n",
      "Epoch 27/50\n",
      "1669/1669 [==============================] - 86s 52ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0923 - val_accuracy: 0.9834\n",
      "Epoch 28/50\n",
      "1669/1669 [==============================] - 88s 53ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0866 - val_accuracy: 0.9843\n",
      "Epoch 29/50\n",
      "1669/1669 [==============================] - 84s 51ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0952 - val_accuracy: 0.9832\n",
      "Epoch 30/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0813 - val_accuracy: 0.9843\n",
      "Epoch 31/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.1148 - val_accuracy: 0.9820\n",
      "Epoch 32/50\n",
      "1669/1669 [==============================] - 84s 51ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0954 - val_accuracy: 0.9840\n",
      "Epoch 33/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0841 - val_accuracy: 0.9843\n",
      "Epoch 34/50\n",
      "1669/1669 [==============================] - 88s 53ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.1030 - val_accuracy: 0.9839\n",
      "Epoch 35/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0944 - val_accuracy: 0.9814\n",
      "Epoch 36/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1069 - val_accuracy: 0.9843\n",
      "Epoch 37/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0949 - val_accuracy: 0.9831\n",
      "Epoch 38/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0869 - val_accuracy: 0.9839\n",
      "Epoch 39/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0959 - val_accuracy: 0.9840\n",
      "Epoch 40/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0921 - val_accuracy: 0.9840\n",
      "Epoch 41/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1164 - val_accuracy: 0.9837\n",
      "Epoch 42/50\n",
      "1669/1669 [==============================] - 84s 50ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1318 - val_accuracy: 0.9820\n",
      "Epoch 43/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0958 - val_accuracy: 0.9825\n",
      "Epoch 44/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.1048 - val_accuracy: 0.9839\n",
      "Epoch 45/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1149 - val_accuracy: 0.9837\n",
      "Epoch 46/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0998 - val_accuracy: 0.9822\n",
      "Epoch 47/50\n",
      "1669/1669 [==============================] - 83s 50ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1157 - val_accuracy: 0.9818\n",
      "Epoch 48/50\n",
      "1669/1669 [==============================] - 87s 52ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.1143 - val_accuracy: 0.9834\n",
      "Epoch 49/50\n",
      "1669/1669 [==============================] - 86s 51ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.1113 - val_accuracy: 0.9826\n",
      "Epoch 50/50\n",
      "1669/1669 [==============================] - 85s 51ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.1274 - val_accuracy: 0.9829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x219dbb56990>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "X, X_test, Y, y_test = train_test_split(padded_sequences, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,Y,test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0735f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/522 [==============================] - 9s 17ms/step - loss: 0.1392 - accuracy: 0.9810\n",
      "Test Loss: 0.13919325172901154, Test Accuracy: 0.9810065627098083\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86685a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArnabBiswas\\anaconda3\\envs\\mlenv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('text_classification_lstm_model.h5')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('text_classification_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea8abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
